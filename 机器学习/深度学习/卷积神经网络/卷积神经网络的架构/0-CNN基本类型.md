主要是想介绍下常用的几种卷积神经网络。卷积神经网络最初为解决图像识别问题而提出，目前广泛应用于图像，视频，音频和文本数据，可以当做深度学习的代名词。
1. 目前图像分类中的ResNet
2. 目标检测领域占统治地位的Faster R-CNN
3. 分割中最牛的Mask-RCNN, UNet和经典的FCN

都是以下面几种常见网络为基础。
- LeNet
- AlexNet
- VggNet
- GoogLeNet
- ResNet
## LeNet
典型的卷积神经网络，开始阶段都是卷积层以及池化层的相互交替使用，之后采用全连接层将卷积和池化后的结果特征全部提取进行概率计算处理。
## AlexNet
首先我们来看下神经网络的坚守者Hinton在2012年和他的学生Alex Krizhevsky设计的AlexNet，该模型拿到了当年ImageNet竞赛的冠军并从此掀起了一波深度学习的热潮。
![](picture/CNN基本类型-d76a3a88.png)
AlexNet主要由5个卷积层和3个全连接层组成，最后一个全连接层通过softmax最终产生的结果作为对于输入图片在1000个类别（ILSVRC图片分类比赛有1000个类别）上的得分。
#### AlexNet是第一个使用卷积神经网络在ILSVRC获得冠军的网络结构，它有如下几个特点：
1. 使用ReLU作为激活函数：为了加快深度神经网络的训练速度，AlexNet将传统神经网络神经元激活函数为f(x) = tanh(x)或 f(x) = (1 + e-x)-1改为f(x) = max(0; x)，即Rectified Linear Units（ReLUs）。从图1.可以看出，从一个含有4层卷积的神经网络上看，ReLUs相比tanh作为激活函数收敛速度要快上几倍。当训练误差同在25%时，ReLUs约5次迭代即可达到tanh迭代约35次的效果。
经过表1的分析可知，AlexNet有超过6千万的参数，虽然ILSVRC比赛有大量的训练数据，但仍很难完成对如此庞大参数的完全训练，从而导致严重的过拟合问题。AlexNet很巧妙地用下面两种方法处理这两个问题：
    1. 数据增强：在图像领域，最简单也最常用的避免过拟合的方法就是对数据集的增强。这里介绍几种数据增强的方法。
    1） 对原始图片做随机裁剪。如原始输入图片大小为256*256，那么训练时随机从256\*256的图片上裁剪224\*224的图片作为网络的输入。
    2） 找到原始图片RGB三个通道对应的主成分（PCA）
    3)另外还有一些常见数据增强的方法，如训练时对原始图片进行随机上下、左右翻转，平移，缩放，旋转等。
    2. 使用dropout：该想法一个是为了避免过拟合再一个是使用更有效的方式进行模型融合。具体方法是在训练时让神经网络中每一个中间层神经元以0.5的概率置为0。当某个神经元被置为0时，它便不会参与前向传播以及反向回传的计算。因此每当有一个新的图片输入就意味着网络随机采样出一个新的网络结构，而真正整个网络的权重一直是共享的。从感性的角度讲，dropout的存在强迫神经网络学习出更稳定的特征。预测时使用所有神经元但将其输出均乘以0.5。

2012年AlexNet使用8层神经网络已top1分类误差16.4%的成绩摘得ILSVRC的桂冠，2013年ZFNet在AlexNet基础上做了超参的调整，使top1误差降到11.7%并成为新的冠军。ZFNet将AlexNet第一个卷积层的kernel从11*11，stride为4改为7*7，stride为2；第三、四、五层卷积的kernel个数从384、384、256分别改为512、1024和512。2014年Simonyan和Zisserman设计了层次更深并且kernel更小的VGGNet。

## VGGNet

先来看下VGGNet的网络结构：
![](picture/CNN基本类型-fce3415b.png)
VGGNet有两种结构分别为16层和19层，从图3可以看出，VGGNet结构所有卷积层的kernel都只有3\*3。VGGNet中连续使用3组3\*3kernel（stride为1）的原因是它和使用1个7\*7kernel产生的效果相同（图4.以一维卷积为例解释效果相同的原理），然而更深的网络结构会学习到更复杂的非线性关系使得模型效果更好。该操作带来的另一个好处是参数数量的减少，因为对于一个有C个kernel的卷积层来说，原来的参数个数为7\*7\*C，而新的参数个数为3\*（3\*3\*C）。![](picture/CNN基本类型-b12c5095.png)
## GoogLeNet
GoogLeNet最初始的想法很简单，想要更好的预测效果那么就增加网络的复杂度，即从两个角度出发：网络深度和网络宽度。但这个思路有两个较为明显的问题，首先更复杂的网络意味着更多的参数，就算是ILSVRC这种有1000类标签的数据也很容易过拟合。其次，更复杂的网络带来更大的计算资源的消耗，而且当kernel个数设计不合理导致kernel中参数没有被完全利用（多数权重都趋近0）时，会导致大量计算资源的浪费。

GoogLeNet引入inception结构来解决这个问题，这里面设计大量的数学推导和原理，感兴趣的读者可参考GoogLeNet原文，这里以一个简单的方式解释inception设计的初衷。首先神经网络的权重矩阵是稀疏的，如果能将图5.中左式的稀疏矩阵和2\*2的矩阵卷积转换成右边2个子矩阵和2\*2矩阵做卷积的方式则会大大降低计算量。那么同样的道理，应用在降低卷积神经网络的计算量上就产生了图6.的inception结构。在这个结构中，将256个均匀分布在3\*3尺度的特征转换成多个不同尺度的聚类，如96个1\*1,96个3*3和64个5\*5分别聚在一起，这样可以使计算更有效，收敛更快。
![](picture/CNN基本类型-0d8ba2fb.png)
## ResNet
2015年何凯明提出152层的ResNet以top1误差3.6%的图像识别记录获得了2015年ILSVRC比赛的冠军，同时也使得卷积神经网络有了真正的“深度”。ResNet的提出是革命性的，它为解决神经网络中因为网络深度导致的“梯度消失”问题提供了一个非常好的思路。

这里解释一下“梯度消失”问题。首先从前面AlexNet到VGGNet再到GoogLeNet，大家可以看出更深层次的网络可以带来更好的识别效果。那么是不是网络结构越深、卷积层数量堆叠得越多越好呢？这里有个简单的实验，从图9.我们可以看出，56层的卷积神经网络无论在训练还是预测的误差都大于20层的网络，所以可以排除过拟合的干扰因素。真实的原因是“梯度消失”，下面我们简单看下原理。
![](picture/CNN基本类型-12d506c2.png)
![](picture/CNN基本类型-8107168b.png)
除残差结构以外，ResNet也沿用了前人一些可以提升网络性能和效果的设计，如堆叠式残差结构，每个残差模块又由多个小尺度kernel组成，整个ResNet除最后用于分类的全连接层以外是全卷积的，这也大大提升了计算速度。ResNet网络深度有34、50、101、152等多种，对于50层以上的ResNet，也借鉴了类似GoogLeNet的思想，在细节上使用了bottleneck的设计方式。
![](picture/CNN基本类型-ace3b4a8.png)
