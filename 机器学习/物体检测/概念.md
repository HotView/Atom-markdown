早期的工作
## R-CNN
R-CNN：基于区域的region-CNN，核心思想，就是对每张图片选取多个区域，然后对每个区域作为一个样本进入一个卷积神经网络来抽取特征，最后使用分类器来对齐分类（启发式搜索）。

随机选择很多的patch，小的region，（每个框的形状是不一样的，大约2000次，每个patch大约是256维度）。==这里的卷积神经网络主要是抽取特征，然后进行SVM的单分类，如果要识别K个物体大约需要K和SVM分类器。==
## Fast R-CNN
有两点改进了性能
- 考虑到R-CNN里面的大量区域可能是相互覆盖的，每次重新抽取特征过于浪费，因此，Fast R-CNN先对图片进行特征抽取，然后再选取区域
- 代替R-CNN使用多个SVM来做分类，Fast R-CNN使用单个多类逻辑回归，这也是经常使用的。
## Faster R-CNN
Fast R-CNN通常需要在选择性搜索中生成较多的提议区域，以获得较精确的目标检测结果。Faster R-CNN提出将选择性搜索替换成区域提议网络（region proposal network），从而减少提议区域的生成数量，并保证目标检测的精度。
## Mask R-CNN
如果训练数据还标注了每个目标在图像上的像素级位置，那么Mask R-CNN能有效利用这些详尽的标注信息进一步提升目标检测的精度。
## SSD模型
单发多框检测器
在R-CNN系列模型里，区域提议和分类是分作两块来进行的。SSD则将其统一成一个步骤来使得模型更加简单并且速度更快，这也是为什么它被称为单发的原因。
==与Faster R-CNN主要有两点不一样：==
- 对于锚框，我们不再首先判断它是不是含有感兴趣的物体，再将正类框放入真正物体分类。SSD使用一个num_class+1类分类器来判断对应是哪类物体，还只是背景。我们也不再有额外的回归器对边框再进一步预测，而是直接使用单个回归器来预测真实边框。
- SSD不只是对卷积神经网络输出的特征做预测，它会进一步将特征通过卷积核池化层变小来做预测，这样达到多尺度预测的效果。
## YOLO只需要看一遍
比SSD更加简单，SSD生成大量的锚框，相对yolo锚框重叠，covre性就比较好，结果比较精细！

将图片特征均匀切成S*S块，每一块当做一个锚框，每个锚框预测B个边框。
- 图片Conv--》直接分为9个不重叠小区域，Softmax和BBox Reg，细节处理不是很好，最后一层用全连接来做的，没有利用空间信息，相对卷积来说。

## YOLOv2
更好，更快，更强
- 使用更好的卷积神经网络来做特征提取，使用更大输入图片448*448使得特征输出大小增大到13*13
- 不均匀切开分割图片特征，而是对训练数据做聚类，然后使用聚类中心最为锚框。
