## 过拟合
训练数据的损失（成本）函数值较小，交叉数据的损失函数值较大
- 样本少。参数过多
- 增加样本数，理论上越多越好
- 通过正则化来消除过拟合
## 欠拟合
训练数据的损失（成本）函数值较大，交叉数据的损失函数值较大
- 模型太简单了。
- 增加有价值的特征，增加多项式特征。

## 正则化
$\lambda\sum{\theta_{j}^2}$
正则项系数的目的有两个：要维持对训练样本的拟合，又要避免对训练样本的过拟合，起一个调节作用,如果值太大，能确保不出现过拟合，可能出现欠拟合现象.

原理上看，成本函数增加一个正则项之后，成本函数不再唯一地由预测值与真实值的误差所决定，还和参数Theta的大小有关。
有了这个限制之后，要实现成本函数最小的目的，Theta就不能随便取值，如果取得过大，导致成本函数也会变大，通过调节lambda，控制权重，避免线形回归算法出现过拟合
## L1/L2范数
L1范数，会让模型参数Theta稀疏化，既让模型参数向量里为0的元素尽量多，而L2范数作为正则项，则是让模型参数尽量小，但不会为0，即尽量让每个特征对预测值都有一些小的贡献。
