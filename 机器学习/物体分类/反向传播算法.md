反向传播依赖于正向传播，而且如果有多个分支流，那最后就是相加即可。
## 梯度下降
![](picture/反向传播算法-e280293e.png)
参数theta：${W1,W2,W3,W4,.....，B1,B2,B3,B4,...}$
选一个初始参数theta0，对loss的偏微分,然后更新theta1即可。
#### 链式法则
![](picture/反向传播算法-05ff9b0c.png)
## Forward pass和Backward pass
![](picture/反向传播算法-5ba9414e.png)
#### Forward pass
计算的结果就是上一层的输入，只看前面接的input：
![](picture/反向传播算法-e167a9ee.png)
#### Backward pass
a = active(z)
计算loss对z的偏微分,等于a对z的偏微分乘以loss对a的偏微分。
![](picture/反向传播算法-4728e50a.png)
![](picture/反向传播算法-3ae2eef7.png)
![](picture/反向传播算法-fc321d07.png)
- 如果是最后一个layer：
![](picture/反向传播算法-089bd80e.png)
- 如果不是最后一个layer：
![](picture/反向传播算法-f2363bee.png)

所以经过以上分析可以知道，计算权重从输出开始，就比较简单。
逆着方向，可以求出所有的loss对z的偏微分。
![](picture/反向传播算法-82739549.png)
## 总结summary
计算loss对某一层W的偏微分，即链式法则，引出激活值z，然后求loss对z的偏微分和z对W的偏微分，将两者相乘即可。
![](picture/反向传播算法-c14b5fd3.png)
## 对于池化层的反向传播
mean_pool：将梯度平均
max_pool：返回一个最大的，其他的为零。
