## 监督学习
#### 支持向量机
通过寻找分类超平面进而最大化类别间隔实现分类
#### 人工神经网络
#### 逻辑回归
通过拟合曲线实现分类（或者学习超平面）
#### 决策树
通过寻找最佳划分特征进而学习样本路径实现分类，主要的决策树模型有三种：
- ID3
- ID4.5
- CART算法：既能创建分类树，也可以创建回归树


#### k近邻
#### 随机森林
对于一个复杂的分类问题，训练一个复杂的分类模型通常比较好费时间，同时，为了提高准确性，通常可以选择多个分类模型，并将各自的预测结果组合起来，得到最终的预测结果。

集成学习就是这样一种学习方法：将多种学习算法，通过适当的方式组合起来，主要分为Bagging和Boosting

随机森林就是Bagging中最重要的一种算法。由很多的分类树构成。
## 朴素贝叶斯
#### 线性回归
#### 回归树
## 非监督学习
#### 聚类
#### PCA
#### 隐马尔科夫模型
推测的变量必须是离散的状态转移，观测值的可以是连续型的变量。x,z-->f z是一个隐含变量（因为z看不见，所以就被称为无监督学习），可以通过x推测出数据变量，例如：天气（z）本身不能直接观测，而是看豆子的干燥程度（x）去推测。
主要有三个问题：

问题一：知道骰子有几种（隐含状态数量），每种骰子是什么（转换概率），根据骰子掷出的结果（可见状态链），想知道每次掷出的都是哪种骰子（隐含状态链）

问题二：知道骰子有几种（隐含状态数量），每种骰子是什么（转换概率），根据骰子掷出的结果（可见状态链），想知道掷出这个结果的原因

问题三：知道骰子有几种（隐含状态数量），不知道每种骰子是什么（转换概率），根据骰子掷出的结果（可见状态链），想反推出每种骰子是什么（转换概率）

要解决的问题：
- 通过观测的序列来推测出最可能的结果的变化，比如写一个数字，随着写的笔画越多，推测出某一个数字的可能性越来越大。
- 学习出一个转移矩阵和观测矩阵

例子：
- 例子：GPS与汽车位置关联关系。

计算模型
- 简单的概率图模型
- 前后向算法：本质就是简单的动态规划，将指数级复杂度降到多项式级的复杂度。
#### 因子分析
