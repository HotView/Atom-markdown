所有的字符在计算机上存储都是以字节的形式进行存储的，只是对应不同的编码格式，每个字符所占用的字节数不相同
- ascii：占用一个字节，定义了128个字符编码，只占用字节的前7位
- EASCII：支持西欧的字符，使用一个字节，使用了8位
- GB2312：使用2个字节，6700+汉字，兼容ascii。
- GBK：中文的编码，收录27484个汉字，兼容ascii
- Unicode：解决全球编码的统一问题，涵盖所有的文字和二进制的对应关系，2-4个字节，收录136690个字符
>Unicode起到了两个作用
>- 直接支持全球所有的语言，每个国家可以不再使用自己的旧编码，使用unicode就可以了
>- unicode包含了全球所有国家编码的映射关系，比如你的gbk编码字符，unicode自动知道它在unicode中的编码是什么，所以无论你以什么编码数据存储数据，只要你的软件在把数据从硬盘读到内存里，转换为unicode来显示就可以了。==Unicode是一个字符集，定义了所有字符与二进制的对应关系。==![enter image description here](https://pic3.zhimg.com/80/v2-8222d78655d3b00c676c48641df8e8a7_hd.jpg)
- **UTF 是为unicode编码设计的一种在存储和传输时节省空间的编码方案。**
- UTF-8：使用1,2,3,4个字节，优先使用1个，无法满足增加一个，最多四个，英文一个，欧西东亚3个，其他4个
- UTF-16：使用2,4个字节表示，优先使用2个，否则使用4个
- UTF-32：使用4个字节表示
## python中的编码
python中文本总是`Unicode`,由`str`类型进行表示，二进制数据使用`bytes`进行表示，不会将`str`与`bytes`偷偷的混在一起，使得两者的区别更加明显。

bytes（字节）通过decode（）转换为str（字符串）
str（字符串）通过encode（）转换为bytes（字节二进制）
在python3中，encode（）和decode（）默认使用UTF-8
**ASCII 、unicode 是字符集，utf-8是字符集的编码方式。**
**utf-8 是 unicode 字符集一种编码方式。**

python3使用unicode字符集，而python2使用ASCII，所以python2使用中文很麻烦

字符串通过编码成为字节码，字节码通过解码成为字符串。
- 编码就是将字符串转换成字节码，涉及到字符串的内部表示。  
- 解码就是将字节码转换为字符串，将比特位显示成字符。
## Unicode 介绍

世界经济日益全球化的同时，一个应用程序需要在全球范围内使用势在必然，基于 Unicode 的应用程序能够很好地处理来自世界各地的用户文本，并适应其文化习俗。 它通过消除每种语言的构建，安装和维护更新来最大限度地降低成本。Unicode（与其并行 ISO 10646 标准）标准除了覆盖全球所有地区国家使用的字符外，它还定义了一系列文本处理的数据和算法，极大简化了 Unicode 的应用，并确保所有遵守其标准的软件产生相同的结果。在过去十年的广泛应用中，Unicode 成为互联网的基石。

Unicode 编码字符集旨在收集全球所有的字符，为每个字符分配唯一的字符编号即代码点（Code Point），用 U+紧跟着十六进制数表示。所有字符按照使用上的频繁度划分为 17 个平面（编号为 0-16），即基本的多语言平面和增补平面。基本的多语言平面（英文为 Basic Multilingual Plane，简称 BMP）又称平面 0，收集了使用最广泛的字符，代码点从 U+0000 到 U+FFFF，每个平面有 216=65536 个码点；增补平面从平面 1~16，分为增补多语言平面（平面 1）、增补象形平面（平面 2）、保留平面（平 3~13）、增补专用平面等，每个增补平面也有 216=65536 个码点。所以 17 个平总计有 17 × 65,536 = 1,114,112 个码点。图 1 是 Unicode 平面分布图，图 2 是 Unicode 各个平面码点空间。

##### 图 1. Unicode 17 个平面分布

![](https://www.ibm.com/developerworks/cn/java/unicode-programming-language/image001.jpg)

##### 图 2. Unicode 平面分布和码点空间

![](https://www.ibm.com/developerworks/cn/java/unicode-programming-language/image002.jpg)

下面是一些相关术语的解释：

Coded Character Set **（CCS）：** 即编码字符集，给字符表里的抽象字符编上一个数字，也就是字符集合到一个整数集合的映射。这种映射称为编码字符集，Unicode 字符集就是属于这一层的概念；

Character Encoding Form **（CEF**）**：即字符编码表，根据一定的算法，将编码字符集（CCS） 中字符对应的码点转换成一定长度的二进制序列，以便于计算机处理，这个对应关系被称为字符编码表，UTF-8、 UTF-16 属于这层概念；

**Code Point:** 码点，简单理解就是字符的数字表示。一个字符集一般可以用一张或多张由多个行和多个列所构成的二维表来表示。二维表中行与列交叉的点称之为码点，每个码点分配一个唯一的编号，称之为码点值或码点编号，除开某些特殊区域(比如代理区、专用区)的非字符码点和保留码点，每个码点唯一对应于一个字符。

**Code Unit**：代码单元，是指一个已编码的文本中具有最短的比特组合的单元。对于 UTF-8 来说，代码单元是 8 比特长；对于 UTF-16 来说，代码单元是 16 比特长。换一种说法就是 UTF-8 的是以一个字节为最小单位的，UTF-16 是以两个字节为最小单位的。

**Code Space**：码点空间，字符集中所有码点的集合。

**BOM** （****Byte Order Mark****）：**字节序，出现在文件头部，表示字节的顺序，第一个字节在前，就是"大头方式"（Big-Endian），第二个字节在前就是"小头方式"（Little-Endian）。这两个古怪的名称来自英国作家斯威夫特的《格列佛游记》，在该书中，小人国里爆发了内战，战争起因是人们争论，吃鸡蛋时究竟是从大头(Big-Endian)敲开还是从小头(Little-Endian)敲开。为了这件事情，前后爆发了六次战争，一个皇帝送了命，另一个皇帝丢了王位。
## Unicode 几种常见编码方式


Unicode 字符集中的字符可以有多种不同的编码方式，如 UTF-8、UTF-16、UTF-32、压缩转换等。这里的 UTF 是 Unicode transformation format 的缩写，即统一码转换格式，将 Unicode 编码空间中每个码点和字节序列进行一一映射的算法。下面详细介绍一下这三种常见的 Unicode 编码方式。

**_UTF-8_****_编码方式_**

UTF-8 是一种变长的编码方式，一般用 1~4 个字节序列来表示 Unicode 字符，也是目前应用最广泛的一种 Unicode 编码方式，但是它不是最早的 Unicode 编码方式，最早的 Unicode 编码方式是 UTF-16。UTF-8 编码算法有以下特点：

1.  **首字节码用来区分采用的编码字节数**：如果首字节以 0 开头，表示单字节编码；如果首字节以 110 开头，表示双字节编码；如果首字节以 1110 开头，表示三字节编码，以此类推；
2.  除了首字节码外，**用 10 开头表示多字节编码的后续字节**，图 3 列出 UTF-8 用 1~6 个字节所表示的编码方式和码点范围（实际上 1~4 个字节基本可以覆盖大部分 Unicode 码点）；
3.  **与 A****SCI****I 编码方式完全兼容**：U+0000 到 U+007F 范围内(十进制为 0~127)的 Unicode 码点值所对应的字符就是 ASCII 字符集中的字符，用一个字节表示，编码方式和 ASCII 编码一致；
4.  **无字节序**，在 UFT-8 编码格式的文本中，如果添加了 BOM，则标示该文本是由 UTF-8 编码方式编码的，而不用来说明字节序。

##### 图 3. UTF-8 编码方式

![](https://www.ibm.com/developerworks/cn/java/unicode-programming-language/image003.jpg)

在实际的解码过程中：

**情况 1：**读取到一个字节的首位为 0，表示这是一个单字节编码的 ASCII 字符；

**情况 2：**读取到一个字节的首位为 1，表示这是一个多字节编码的字符，如继续读到 1，则确定这是首字节，在继续读取直到遇到 0 为止，一共读取了几个 1，就表示在字符为几个字节的编码；

**情况 3：**当读取到一个字节的首位为 1，紧接着读取到一个 0，则该字节是多字节编码的后续字节。

图 4 概述了 UTF-8 编码方式的特点，其中的"**自同步**"表示在传输过程中如果有字节序列丢失，并不会造成任何乱码现象，或者存在错误的字节序列也不会影响其他字节的正常读取。例如读取了一个 10xxxxxx 开头的字节，但是找不到首字节，就可以将这个后续字节丢弃，因为它没有意义，但是其他的编码方式，这种情况下就很可能读到一个完全不同或者错误的字符。

##### 图 4. UTF-8 编码方式

![](https://www.ibm.com/developerworks/cn/java/unicode-programming-language/image004.jpg)

**_UTF-16_****_编码方式_**

UTF-16 是最早的 Unicode 字符集编码方式，在概述 UTF-16 之前，需要解释一下 USC-2 编码方式，他们有源远流长的关系，UTF-16 源于 UCS-2。UCS-2 将字符编号（同 Unicode 中的码点）直接映射为字符编码，亦即字符编号就是字符编码，中间没有经过特别的编码算法转换。图 5 对 UCS-2 编码方式的概括。

##### 图 5. UCS-2 编码方式

![](https://www.ibm.com/developerworks/cn/java/unicode-programming-language/image005.jpg)

由图 5 可知，UCS-2 编码方式只覆盖基本多语言平面的码点，因为 16 位二进制表示的最大值为 0xFFFF，而对于增补平面中的码点（范围为 0x10000~0x10FFFF，十进制为 65536~1114111），两字节的 16 位二进制是无法表示的。为了解决这个问题，The Unicode Consortium 提出了通过代理机制来扩展原来的 UCS-2 编码方式，也就是 UTF-16。其编码算法如下：

1.  基本多语言平面（BMP）中有效码点用固定两字节的 16 位代码单元为其编码，其数值等于相应的码点，桶 USC-2 的编码方式；
2.  辅助多语言平面 1-16 中的有效码点采用代理对（surrogate pair）对其编码：用两个基本平面中未定义字符的码点合起来为增补平面中的码点编码，基本平面中这些用作"代理"的码点区域就被称之为"代理区(Surrogate Zone)"，其码点编号范围为 0xD800~0xDFFF(十进制 55296~57343)，共 2048 个码点。代理区的码点又被分为高代理码点和低代理码点，高代理码点的取值范围为 0xD800~0xDBFF，低代理码点的取值范围为 0xDC00~0xDFFF，高代理码点和低代理码点合起来就是代理对，刚好可以表示增补平面内的所有码点，如图 6 所示。

##### 图 6. UTF-16 代理对

![](https://www.ibm.com/developerworks/cn/java/unicode-programming-language/image006.jpg)

但是在实际的编码过程中通过查表是很麻烦的，图 7 列出了 UTF-16 编码算法是如何对增补平面中的码点进行编码的。

##### 图 7. UTF-16 编码算法剖析

![](https://www.ibm.com/developerworks/cn/java/unicode-programming-language/image007.jpg)

UTF-16 对增补平面中的码点编码还是很负责的，但是由于 UTF-16 是最早的 Unicode 编码方式，已经存在于很多程序中。

**_UTF-32(UCS-4)_****_编码方式_**

UTF-32 是一个以固定四字节编码方式，ISO 10646 中称其为 UCS-4 的编码机制的子集。优点是每一个 Unicode 码点都和 UTF-16 的 Code Unit 一一对应，程序中如果采用 UTF-32 处理起来比较简单，但是所有的字符都用四个字节，特别浪费空间，所以实际上使用比较少。其特性如图 6 所示。

##### 图 8. UTF-32 编码

![](https://www.ibm.com/developerworks/cn/java/unicode-programming-language/image008.jpg)

1

`UTF-16 和 UTF-32 的最小 Code Unit（编码单元）是双字节即 16 个比特位，即多字节编码方式，因此这两种编码方式都存在字节序标记（BOM）问题。`

-   **Big-Endian****（****BE****）即大端序****：**就是高位字节(即大端字节)存放在内存的低地址，低位字节(即小端字节)存放在内存的高地址。UTF-16(BE)以 FEFF 作为开头字节，UTF-32(BE)以 00 00 FE FF 作为开头字节；
-   **Little-Endian (LE)****即小端序****：**低位字节(即小端字节)存放在内存的低地址，而高位字节(即大端字节)存放在内存的高地址。UTF-16(LE)以 FFFE 作为开头字节，UTF-32(LE)以 FF FE 00 00 作为开头字节。
-   UTF-8  **不需要**  BOM  **来表明字节顺序：**可以用 BOM（EF BB BF 称为零宽无间断间隔）来表明编码方式，如果接收者收到以 EF BB BF 开头的字节流，就知道这是 UTF-8 编码。
## Unicode 支持在 Java Web 程序中应用实践

Unicode 是互联网的基石，为了保证我们的 Web 应用程序很好的支持 Unicode 标准。从代码角度需要考虑 Unicode 支持的地方有（不限于这些，下面是基于笔者项目实践）：

**J****av****a 默认字符集设定**：通常情况下如 Windows 系统，我们会通过设置环境变量 JAVA_TOOL_OPTIONS 将默认编码更改为 UTF-8，下面是 Java 程序默认字符集的优先级顺序：

1.  程序执行时使用 Properties 指定的字符集，如 System.getProperties().put("file.encoding","UTF-8);
2.  参数-Dfile.encoding 指定的字符集，如 Windows 可以通过设置环境变量 JAVA_TOOL_OPTIONS=-Dfile.encoding=UTF-8
3.  操作系统默认的字符集；
4.  JDK 中 JVM 默认的字符集。

**JSP****：**通过 JSP 页面命令<%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%>设置 JSP 页面的编码方式（pageEncoding）以及提交表单时所使用的编码方式（charset 属性）；

**H****TML:**

设置 Content-Type 属性<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">；

**Servlet****：**设置 response.setContentType("text/html;charset=UTF-8")，即服务器端编码方式；

**POST****请求：**

通过 request.setCharacterEncoding ("UTF-8")设置解码方式、response.setCharacterEncoding("UTF-8")设置服务器端响应数据的编码方式，如清单 3 所示；

##### 清单 3. POST 请求字符编码设置

```
protected void service(HttpServletRequest request, HttpServletResponse`
response) throws ServletException, IOException {`
// TODO Auto-generated method stub`
request.setCharacterEncoding("UTF-8");`
response.setCharacterEncoding("UTF-8");`
}
```

**Get** 请求：**Get 请求方式中请求参数会被附加到地址栏的 URL 之后，URL 组成：域名:端口/contextPath/servletPath/pathInfo?queryString，不同的服务器对 URL 中 pathInfo 和 queryString 解码方式设定不一样，比如 Tomcat 服务器一般在 server.xml 中设定的，Tomcat8 之前的版本默认使用的是 ISO-8859-1，但是 Tomcat 8 默认使用的是 UTF-8，如清单 4 所示；另外对于双字节字符如中日韩等作为 URL 的参数时，最好先 URI 编码后在放到 URL 中 URLEncoder.encode(String.valueOf(c),"UTF-8")；

##### 清单 4. Tomcat server.xml 设置

```

`Tomcat server.xml`
<``Connector` `port``=``"8080"` `protocol``=``"HTTP/1.1"
maxThreads``=``"150"
connectionTimeout``=``"20000"
redirectPort``=``"8443"
URIEncoding``=``"UTF-8"
useBodyEncodingForURI``=``"true"``>
```

**XML** 文档设置 transformer.setOutputProperty(OutputKeys.ENCODING, "UTF-8");

**调用 API 时指定字符集：** 调用字符串操作相关或者其他 I/O 操作 API 时，最好指定字符集，如 String.getBytes("UTF-8")，而不是 String.getBytes()；根据情况必要的时候需要写入 BOM 头，例如 Microsoft Office 在读取 csv 文件的时候，它将首先读取 BOM，然后使用 BOM 中的编码打开文件，这种情况下我们在创建或者导出到 CSV 文件的时候，我们需要在代码里面写入 BOM 头。图 10 所示的例子是创建一个 csv 文件的时候没有写入 BOM，用 Office 打开看到的都是乱码，但是用其他编辑器比如 notepad++显示是正常。当加上 BOM 文件头的时候 fos.write(new byte[]{(byte)0xEF,(byte)0xBB, (byte)0xBF}) 用 Office 再次打开就是正确的字符，代码如清单 5 所示。备注一下，UTF-8 虽然部分大端小端序，但是可以加 BOM 头，表示这个文本是 UTF-8 编码。

##### 图 11. 缺少 BOM 标记乱码示例

![](https://www.ibm.com/developerworks/cn/java/unicode-programming-language/image011.jpg)

##### 清单 5. BOM 标记例子
```
`private static void createCsvFile() {`
`try {`
`FileOutputStream fos = new FileOutputStream("c:\\test.csv");`
`String str ="姓名,性别,年龄,出生年月";`
`fos.write(new byte[]{(byte)0xEF,(byte)0xBB, (byte)0xBF});`
`OutputStreamWriter osw = new OutputStreamWriter(fos, "UTF-8");`
`BufferedWriter b_writer = new BufferedWriter(osw);`
`b_writer.write(str);`
`b_writer.close();`
`} catch (IOException e) {`
`System.out.println(e.toString());`
`}`
`}
```
**Oracle 数据库：** Oracle 数据库从 7.2 开始支持 Unicode，为了让应用程序更好的支持多语言，当我们新建一个数据库的时候，最好使用 UTF-8 编码格式，从而可以对如 CHAR、VARCHAR2、CLOB、LONG 等 SQL 数据类型使用 UTF-8 进行编码；如果多语言数据可能只出现在某些字段中，那么也可以直接使用支持 Unicode 编码的 SQL 数据类型，如 NCHAR、NVARCHAR2 和 NCLOB，如表 4 列出的常用 SQL 数据类型介绍。


> Written with [StackEdit](https://stackedit.io/).
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE0Nzk1NTAyNjcsNTAxNTA0MjUyLC0xMz
M2MjM3MDA0LC03ODE0NDg1MzIsOTQxMjkyNzk1LDIwNDUzNjIw
NTIsLTEzMzgxMzA4MDMsLTE1NjQ2OTE5OTMsNzcwMTg4NzJdfQ
==
-->