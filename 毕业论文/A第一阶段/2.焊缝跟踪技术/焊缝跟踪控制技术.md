焊缝定位跟踪控制方法
机器人的视觉伺服技术是指利用图像采集等设备获取的视觉信息与机器人末端执行器的位姿构成闭环控制系统。根据视觉反馈的信号表现形式的不同，视觉伺服主要分为基于位置的视觉伺服（PBVS）和基于图像的视觉伺服（IBVS）。
## 基于位置的视觉伺服
视觉反馈的信息是空间三维信息，该信息具有明确的物理意义，实现起来也比较容易，一个典型的位置伺服的机器人控制系统如图所示：
![enter image description here](https://github.com/HotView/Images/raw/master/TIM%E6%88%AA%E5%9B%BE20190311171015.png)
视觉系统采集图像后，对图像特征进行提取，然后利用机器人与视觉系统的标定关系对机器人末端执行器的期望位姿进行计算，将期望位姿信息反馈回去与机器人的实际位姿进行比较，得到两者的偏差，传入机器人控制器对偏差进行纠正。
系统的偏差信号是空间三维信息，因此基于位置的视觉也被称为==三维视觉伺服==。

基于位置的伺服控制只有位置闭环，没有图像闭环，因此系统的测量精度依赖于系统的标定精度。
## 基于图像的视觉伺服
基于图像的视觉伺服是在图像空间进行闭环控制，直接利用检测的图像特征与期望的图像特征进行偏差的计算，图像的特征直接作为视觉反馈信息，因此对系统的标定误差不敏感。
==重点和难点：==计算图像的雅克比矩阵，图像的雅克比矩阵描述了图像目标点的位置与期望位置之间的差值与机器人运动之间的变化关系，**不需要计算出目标点的三维空间位置**。因此也被称为二维伺服控制，但是，由于系统的偏差信号是图像二维信号，没有明确的物理意义，在图像特征变化较大的情况下容易进入雅克比矩阵的奇异点。下图是视觉伺服控制系统。
![enter image description here](https://github.com/HotView/Images/raw/master/TIM%E6%88%AA%E5%9B%BE20190311171108.png)
#### 在线纠偏
基于初始的示教路径，系统检测的焊缝位置与机器人焊接位置进行比较，机器人在示教运动下进行纠偏运动，能够适应复杂焊缝的纠偏，不容易受到检测噪声的影响。

#### 在线跟踪
在线跟踪采用引导的方式，没有初始的示教轨迹，机器人根据视觉传感器检测到的焊缝信息进行运动，机器人的姿态也根据检测信息进行控制，但是对复杂焊缝跟踪时无法满足焊接工艺，且容易受到检测噪声的影响。
## 焊缝轨迹在线纠偏控制方法
设计了基于采样周期的在线纠偏算法和前瞻数据存储方式，采用卡尔曼滤波对实时检测焊缝点进行平滑。
根据在线纠偏算法原理，设计了模糊-PI双层控制方法，实现机器人纠偏的快速性和准确性。
对空间圆弧焊缝和空间相贯线焊缝进行了在线纠偏控制实验，焊缝纠偏效果良好，平均误差在正负0.3mm以内。

> Written with [StackEdit](https://stackedit.io/).

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTIwNTYwOTU3NjksLTQ3MzM4OTIzNywxOD
U0NjAwMDY5LDUyOTU1ODMzNSwxNTA3NzUzNzg5LDY5MzAwNzA4
MF19
-->